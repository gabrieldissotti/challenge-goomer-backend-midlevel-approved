# Goomer backend challenge

## ‚ú® O Projeto
O projeto consiste em uma API para cadastro, altera√ß√£o, listagens e exclus√µes de restaurantes e seus produtos, utilizando Node e Typescript.

Nesse README.md busquei trazer bastante argumenta√ß√µes sobre o porque utilizei essas ferramentas e t√©cnicas no projeto.

Veja quais foram os [requisitos para esse desafio](https://github.com/goomerdev/job-dev-backend-interview).

## üìú Manual de execu√ß√£o

Para rodar essa aplica√ß√£o localmente voc√™ pode seguir uma das tr√™s op√ß√µes descritas a seguir.

### Op√ß√£o 1) Rodando com docker compose

Requisitos de ambiente:
- [Docker](https://www.docker.com/products/docker-desktop) vers√£o 20.10.7 ou superior

Ap√≥s instalar os pr√©-requisitos, na raiz do projeto voc√™ pode rodar o seguinte comando para subir a aplica√ß√£o:

```shell
docker compose up development
```
> Aguarde o container subir e pronto, voc√™ j√° pode acessar a aplica√ß√£o em: http://localhost:3333 üòÄ

**Production Ready:** Se voc√™ deseja executar a vers√£o built que vai rodar em produ√ß√£o, execute o comando `docker compose up production`

### Op√ß√£o 2) Rodando manualmente

Requisitos de ambiente:
- [Node](https://nodejs.org/en/) vers√£o 14.17.1 ou superior
- [Yarn](https://yarnpkg.com/) vers√£o 1.22.10 ou superior

Primeiro, rode o comando `yarn` na raiz do projeto para instalar as depend√™ncias

Antes de continuar, precisaremos ter uma base de dados iniciada, pra isso voc√™ pode executar o comando `docker compose up goomerDatabase` ou fazer isso manualmente.

Se optar por subir uma base de dados manualmente certifique-se de ter as vari√°veis de ambiente sobre conex√£o com banco de dados configuradas, voc√™ pode renomear o arquivo .env.example para .env e adicionar os dados de acesso ao seu banco de dados.

Opcionalmente voc√™ pode subir uma inst√¢ncia do redis com o comando `docker compose up goomerRedis` ou instalar o redis na sua maquina manualmente, mas n√£o se preocupe, pois caso a aplica√ß√£o n√£o consiga se conectar com o redis ela ir√° subir normalmente.

Agora voc√™ j√° pode executar a aplica√ß√£o execute o comando `yarn dev`

> Aguarde a aplica√ß√£o subir e pronto, voc√™ j√° pode acessar a aplica√ß√£o em: http://localhost:3333 üòÄ

**Production Ready:** Se voc√™ deseja executar a vers√£o built que vai rodar em produ√ß√£o, execute o comando `yarn build` para gerar o c√≥digo final e use o comando `yarn start` para servir a aplica√ß√£o.

### Op√ß√£o 3) Rodando com docker run

Requisitos de ambiente:
- [Docker](https://www.docker.com/products/docker-desktop) vers√£o 20.10.7 ou superior

Essa √© pra quem gosta de ativar o modo raiz n√≠vel 4 üòÖ ou pra quando houver alguma restri√ß√£o √† usar o compose. Mas se voc√™ s√≥ quer rodar local mesmo recomendo usar a op√ß√£o 1.

Primeiro precisaremos fazer a build da imagem, pra isso rode:

```shell
docker build --file Dockerfile --tag backend --target back_development .
```

Opcionalmente voc√™ pode subir uma inst√¢ncia de redis com o seguinte comando:
```shell
docker run --name goomerRedis  -p 6379:6379 -d redis redis-server --bind '0.0.0.0'
```

> Caso voc√™ n√£o suba essa inst√¢ncia a aplica√ß√£o funcionar√° normalmente, por√©m sem os benef√≠cios na velocidade da resposta da API com cache.

Agora vamos subir um container para a base de dados j√° especificando o arquivo DDL para ser executado:
```shell
docker run --name goomerDatabase -e POSTGRES_PASSWORD=postgres -v ${PWD}/docs/DDL-DML.sql:/docker-entrypoint-initdb.d/docker_postgres_init.sql -d postgres
```

E por fim, para subir o backend, na raiz do projeto execute:
```shell
docker run -it --rm -v ${PWD}:/app -v /app/node_modules -p 3333:3333 -e REDIS_HOST=host.docker.internal -e DATABASE_HOST=host.docker.internal -e NODE_ENV=development backend
```

> Espere os containers subirem e pronto, voc√™ j√° pode acessar a aplica√ß√£o em: http://localhost:3333 üòÄ


**Production Ready:** Se voc√™ deseja executar a vers√£o built que vai rodar em produ√ß√£o, apenas troque o --target para `back_production` ao inv√©s de `back_development` quando for gerar a imagem, o resto do processo √© o mesmo.

## Refer√™ncia da API

Eu geralmente gosto de documentar minhas API's na plataforma stoplight.io, ent√£o vou deixar aqui o [link pra acessar a refer√™ncia da API online](https://qualtrics.stoplight.io/docs/gh/gabrieldissotti/job-dev-backend-interview).

Vou deixar esses links para que voc√™ possa baixar o [arquivo de collection para Postman](./docs/postman.collection.json) ou [o arquivo para Insomnia](./docs/insomnia.collection.json) para fazer as requests √† API localmente caso deseje. Voc√™ pode importar esses arquivos no programa correspondente e j√° deixei alguns payloads prontos para voc√™ usar.

## Arquitetura do projeto

Em resumo, segue uma imagem exibindo o fluxo da requisi√ß√£o pelas camadas da aplica√ß√£o:


![Arquitetura](./docs/media/architecture.png)

A seguir ser√° detalhado a responsabilidade de cada camada da aplica√ß√£o.

### __tests__
Unidade onde criamos todos os arquivos de teste do projeto.

### @types
Para sobrescrever interfaces que j√° existem, como a Request do express, podem ser criados arquivos *.d.ts dentro dessa pasta.

### Configs
√â a camada onde definimos tudo que √© parametriz√°vel da API, facilitando encontrar essas configura√ß√µes caso seja necess√°rio para manutenir a aplica√ß√£o.

### Container
√â onde est√£o as "refer√™ncias" das classes para serem utilizadas na inje√ß√£o de depend√™ncia nas services. Quando forem adicionadas novas classes com inje√ß√£o de depend√™ncia, devem ser mapeadas aqui. Para inje√ß√£o de depend√™ncia utilizamos a biblioteca tsyringe.

### Controllers
Camada de dom√≠nio que tem apenas a responsabilidade de receber a requisi√ß√£o, encaminhar para outra camada lidar e devolver a resposta para o cliente;

### Database
Camada respons√°vel por fazer a conex√£o com o banco de dados.

### Entities
Camada onde ficam as entidades ou models, utilizadas pelas repositories para mapear as rela√ß√µes existentes.

### Exceptions
Camada onde s√£o definidas as classes de exce√ß√µes usadas no projeto para padronizar erros HTTP e outros erros internos.

### Libraries
S√£o bibliotecas com o objetivo de isolar responsabilidades diferentes como exibir logs padronizados, consumir API's ou SDK's.

### Middlewares
S√£o interceptadores de requisi√ß√µes, usados para abstrair l√≥gicas que s√£o √∫teis para a maioria dos fluxos de requisi√ß√£o.

### Repositories
Camada com a responsabilidade de manter toda a abstra√ß√£o de consultas ao banco de dados


### Services
Onde se encontra todas as regras de neg√≥cio. Segui os padr√µes do Service Pattern do Domain-driven Design (DDD) quando criei services com uma √∫nica fun√ß√£o publica `execute()` com a finalidade de isolar responsabilidades.

### Utils
Pasta que contem as constantes, enums e fun√ß√µes comuns √∫teis para qualquer parte do projeto

### Validators
Camada com objetivo de validar os dados recebidos de um payload, query string ou path params para garantir a integridade das informa√ß√µes enviadas pelo cliente.

### Routes
Local onde definimos as rotas (paths) do dom√≠nio e refer√™nciamos a qual controller devemos encaminhar a requisi√ß√£o.

## Banco de dados e modelagem

Dentre os 3 bancos SGBD's para SQL que j√° utilizei (Postgres, MariaDB/MySQL e SQL Server), eu optei em usar o Postgres porque:

- √â um projeto Open Source, sendo assim gratu√≠to n√£o sendo necess√°rio arcar com custos de licen√ßa

- Tem uma comunidade bem grande, ent√£o para quase qualquer problema se encontra facilmente solu√ß√µes em forums na internet.

- Suporta queries em paralelo que usam diferentes n√∫cleos do processador

Sendo assim, esse foi a modelagem do projeto que elaborei com base no problema:


![Diagrama Entidade Relacionamento](./docs/media/DER.png)

[Voc√™ pode ver o DDL clicando aqui](./docs/DDL-DML.sql)

## Outras decis√µes t√©cnicas

- Optei por adicionar redis para fazer cache no endpoint de listagem de produtos e restaurantes, assim aumentando a performance e diminuindo o processamento do lado do servidor, se esse projeto fosse para produ√ß√£o usando um servi√ßo de custo din√¢mico como Lambda da AWS, ter√≠amos uma redu√ß√£o de custos significativa no longo prazo, al√©m de tornar a experi√™ncia do usu√°rio final melhor por ter que esperar menos.
  - O cache est√° configurado para durar 1 minuto, por√©m isso seria algo parametriz√°vel pela vari√°vel de ambiente `REDIS_CACHE_DURATION` e esse tempo seria decidido dependendo do cen√°rio tivermos em ambiente de produ√ß√£o.
  - A chave do cache √© uma string gerada combinado a rota e os query params
  - Quando a API responde com dados em cache, s√£o adicionados os headers `cache_updated_at` e `cache_invalidation_at` para a aplica√ß√£o cliente que possa se integrar saber quando esses dados foram atualizados.

- Optei por utilizar UUID's ao inv√©s de n√∫meros sequenciais porque essa √© uma t√©cnica que pode garantir um pouco mais seguran√ßa dado que seria mais dif√≠cil de descobrir os recursos da mesma natureza, s√£o praticamente infinitos e √© a melhor forma de identificar e relacionar e relacionar objetos dentre um grupo de API's ou bancos de dados distribu√≠dos.

## Testes unit√°rios

Para a maioria dos casos eu utilizei da pr√°tica TDD criando os testes antes de criar a funcionalidade.

- Para gerar cobertura de testes rode `yarn test --coverage`

**Cobertura de Testes**

![Cobertura de testes](./docs/media/coverage.png)

## O que poderia melhorar

- Acredito que eu deveria ter salvo os hor√°rios de funcionamento como um campo string apenas, acho que compliquei demais sem necessidade, acredito que eu s√≥ precisaria ter feito dessa forma com valida√ß√µes de dias da semana e hor√°rios se meu objetivo fosse trabalhar com uma agenda ou algo assim, por outro lado se fosse apenas exibir como uma descri√ß√£o em um app de delivery uma simples string seria mais interessante rs üòÖ.

- Eu poderia colocar algumas l√≥gicas pra tornar aqueles arquivos de Mock das repositories em factories e ao adicionar alguns testes de integra√ß√£o usando a lib `supertest` pra fazer as requests e assim poder garantir o body que o endpoint est√°ria retornando para o cliente.

- Eu poderia ter criado algumas fun√ß√µes privadas pra tornar a leitura da service mais flu√≠da e isolando melhoras as responsabilidades, principalmente as services de update

## ‚åõ Tempo decorrido para execu√ß√£o das tarefas

> Tempo levado para finalizar: 22h 46min

- Modelar banco de dados e gerar script de gera√ß√£o - 2h

- Configurar estrutura do projeto (pastas, database, redis, docker) - 2h 30min

- Cadastrar novos restaurantes - 2h 5min

- Alterar os dados um restaurante - 2h 6min

- Listar os dados de um restaurante - 1h 40min

- Adicionar hor√°rio de funcionamento em restaurantes - 2h

- Listar todos os restaurantes - 20min

- Excluir um restaurante - 51min

- Listar todos os produtos de um restaurante - 40min

- Criar um produto de um restaurante - 1h

- Alterar um produto de um restaurante - 1h 10min

- Excluir um produto de um restaurante - 25min

- Implementar melhorias e revisar c√≥digo e documenta√ß√£o - 4h

- Atualizar Readme - 2h

## Considera√ß√µes finais

Fico a disposi√ß√£o para tirar d√∫vidas e sempre estarei aberto a criticas construtivas e sugest√µes de melhorias, obrigado pela aten√ß√£o!

Contato: gabrieldnrodrigues@gmail.com

Linkedin: https://www.linkedin.com/in/gabrieldissotti/

> Algumas pessoas com quem trabalhei recentemente comentaram no meu perfil do linkedin sobre a experi√™ncia que tiveram em trabalhar comigo, vale dar uma olhada l√° üòÄ.
