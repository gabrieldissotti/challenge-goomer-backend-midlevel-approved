# Goomer backend challenge

## âœ¨ O Projeto
O projeto consiste em uma API para cadastro, alteraÃ§Ã£o, listagens e exclusÃµes de restaurantes e seus produtos, utilizando Node e Typescript.

Nesse README.md busquei trazer bastante argumentaÃ§Ãµes sobre o porque utilizei essas ferramentas e tÃ©cnicas no projeto.

Veja quais foram os [requisitos para esse desafio](https://github.com/goomerdev/job-dev-backend-interview).

## ğŸ“œ Manual de execuÃ§Ã£o

Para rodar essa aplicaÃ§Ã£o localmente vocÃª pode seguir uma das trÃªs opÃ§Ãµes descritas a seguir.

### OpÃ§Ã£o 1) Rodando com docker compose

Requisitos de ambiente:
- [Docker](https://www.docker.com/products/docker-desktop) versÃ£o 20.10.7 ou superior

ApÃ³s instalar os prÃ©-requisitos, na raiz do projeto vocÃª pode rodar o seguinte comando para subir a aplicaÃ§Ã£o:

```shell
docker compose up development
```
> Aguarde o container subir e pronto, vocÃª jÃ¡ pode acessar a aplicaÃ§Ã£o em: http://localhost:3333 ğŸ˜€

**Production Ready:** Se vocÃª deseja executar a versÃ£o built que vai rodar em produÃ§Ã£o, execute o comando `docker compose up production`

### OpÃ§Ã£o 2) Rodando manualmente

Requisitos de ambiente:
- [Node](https://nodejs.org/en/) versÃ£o 14.17.1 ou superior
- [Yarn](https://yarnpkg.com/) versÃ£o 1.22.10 ou superior

Primeiro, rode o comando `yarn` na raiz do projeto para instalar as dependÃªncias

Antes de continuar, precisaremos ter uma base de dados iniciada, pra isso vocÃª pode executar o comando `docker compose up goomerDatabase` ou fazer isso manualmente.

Se optar por subir uma base de dados manualmente certifique-se de ter as variÃ¡veis de ambiente sobre conexÃ£o com banco de dados configuradas, vocÃª pode renomear o arquivo .env.example para .env e adicionar os dados de acesso ao seu banco de dados.

Opcionalmente vocÃª pode subir uma instÃ¢ncia do redis com o comando `docker compose up goomerRedis` ou instalar o redis na sua maquina manualmente, mas nÃ£o se preocupe, pois caso a aplicaÃ§Ã£o nÃ£o consiga se conectar com o redis ela irÃ¡ subir normalmente.

Agora vocÃª jÃ¡ pode executar a aplicaÃ§Ã£o execute o comando `yarn dev`

> Aguarde a aplicaÃ§Ã£o subir e pronto, vocÃª jÃ¡ pode acessar a aplicaÃ§Ã£o em: http://localhost:3333 ğŸ˜€

**Production Ready:** Se vocÃª deseja executar a versÃ£o built que vai rodar em produÃ§Ã£o, execute o comando `yarn build` para gerar o cÃ³digo final e use o comando `yarn start` para servir a aplicaÃ§Ã£o.

### OpÃ§Ã£o 3) Rodando com docker run

Requisitos de ambiente:
- [Docker](https://www.docker.com/products/docker-desktop) versÃ£o 20.10.7 ou superior

Essa Ã© pra quem gosta de ativar o modo raiz nÃ­vel 4 ğŸ˜… ou pra quando houver alguma restriÃ§Ã£o Ã  usar o compose. Mas se vocÃª sÃ³ quer rodar local mesmo recomendo usar a opÃ§Ã£o 1.

Primeiro precisaremos fazer a build da imagem, pra isso rode:

```shell
docker build --file Dockerfile --tag backend --target back_development .
```

Opcionalmente vocÃª pode subir uma instÃ¢ncia de redis com o seguinte comando:
```shell
docker run --name goomerRedis  -p 6379:6379 -d redis redis-server --bind '0.0.0.0'
```

> Caso vocÃª nÃ£o suba essa instÃ¢ncia a aplicaÃ§Ã£o funcionarÃ¡ normalmente, porÃ©m sem os benefÃ­cios na velocidade da resposta da API com cache.

Agora vamos subir um container para a base de dados jÃ¡ especificando o arquivo DDL para ser executado:
```shell
docker run --name goomerDatabase -e POSTGRES_PASSWORD=postgres -v ${PWD}/docs/DDL-DML.sql:/docker-entrypoint-initdb.d/docker_postgres_init.sql -d postgres
```

E por fim, para subir o backend, na raiz do projeto execute:
```shell
docker run -it --rm -v ${PWD}:/app -v /app/node_modules -p 3333:3333 -e REDIS_HOST=host.docker.internal -e DATABASE_HOST=host.docker.internal -e NODE_ENV=development backend
```

> Espere os containers subirem e pronto, vocÃª jÃ¡ pode acessar a aplicaÃ§Ã£o em: http://localhost:3333 ğŸ˜€


**Production Ready:** Se vocÃª deseja executar a versÃ£o built que vai rodar em produÃ§Ã£o, apenas troque o --target para `back_production` ao invÃ©s de `back_development` quando for gerar a imagem, o resto do processo Ã© o mesmo.

## ReferÃªncia da API

Eu geralmente gosto de documentar minhas API's na plataforma stoplight.io, entÃ£o vou deixar aqui o [link pra acessar a referÃªncia da API online](https://qualtrics.stoplight.io/docs/gh/gabrieldissotti/job-dev-backend-interview).

Vou deixar esses links para que vocÃª possa baixar o [arquivo de collection para Postman](./docs/postman.collection.json) ou [o arquivo para Insomnia](./docs/insomnia.collection.json) para fazer as requests Ã  API localmente caso deseje. VocÃª pode importar esses arquivos no programa correspondente e jÃ¡ deixei alguns payloads prontos para vocÃª usar.

## Arquitetura do projeto

Em resumo, segue uma imagem exibindo o fluxo da requisiÃ§Ã£o pelas camadas da aplicaÃ§Ã£o:


![Arquitetura](./docs/media/architecture.png)

A seguir serÃ¡ detalhado a responsabilidade de cada camada da aplicaÃ§Ã£o.

### __tests__
Unidade onde criamos todos os arquivos de teste do projeto.

### @types
Para sobrescrever interfaces que jÃ¡ existem, como a Request do express, podem ser criados arquivos *.d.ts dentro dessa pasta.

### Configs
Ã‰ a camada onde definimos tudo que Ã© parametrizÃ¡vel da API, facilitando encontrar essas configuraÃ§Ãµes caso seja necessÃ¡rio para manutenir a aplicaÃ§Ã£o.

### Container
Ã‰ onde estÃ£o as "referÃªncias" das classes para serem utilizadas na injeÃ§Ã£o de dependÃªncia nas services. Quando forem adicionadas novas classes com injeÃ§Ã£o de dependÃªncia, devem ser mapeadas aqui. Para injeÃ§Ã£o de dependÃªncia utilizamos a biblioteca tsyringe.

### Controllers
Camada de domÃ­nio que tem apenas a responsabilidade de receber a requisiÃ§Ã£o, encaminhar para outra camada lidar e devolver a resposta para o cliente;

### Database
Camada responsÃ¡vel por fazer a conexÃ£o com o banco de dados.

### Entities
Camada onde ficam as entidades ou models, utilizadas pelas repositories para mapear as relaÃ§Ãµes existentes.

### Exceptions
Camada onde sÃ£o definidas as classes de exceÃ§Ãµes usadas no projeto para padronizar erros HTTP e outros erros internos.

### Libraries
SÃ£o bibliotecas com o objetivo de isolar responsabilidades diferentes como exibir logs padronizados, consumir API's ou SDK's.

### Middlewares
SÃ£o interceptadores de requisiÃ§Ãµes, usados para abstrair lÃ³gicas que sÃ£o Ãºteis para a maioria dos fluxos de requisiÃ§Ã£o.

### Repositories
Camada com a responsabilidade de manter toda a abstraÃ§Ã£o de consultas ao banco de dados


### Services
Onde se encontra todas as regras de negÃ³cio. Segui os padrÃµes do Service Pattern do Domain-driven Design (DDD) quando criei services com uma Ãºnica funÃ§Ã£o publica `execute()` com a finalidade de isolar responsabilidades.

### Utils
Pasta que contem as constantes, enums e funÃ§Ãµes comuns Ãºteis para qualquer parte do projeto

### Validators
Camada com objetivo de validar os dados recebidos de um payload, query string ou path params para garantir a integridade das informaÃ§Ãµes enviadas pelo cliente.

### Routes
Local onde definimos as rotas (paths) do domÃ­nio e referÃªnciamos a qual controller devemos encaminhar a requisiÃ§Ã£o.

## Banco de dados e modelagem

Dentre os 3 bancos SGBD's para SQL que jÃ¡ utilizei (Postgres, MariaDB/MySQL e SQL Server), eu optei em usar o Postgres porque:

- Ã‰ um projeto Open Source, sendo assim gratuÃ­to nÃ£o sendo necessÃ¡rio arcar com custos de licenÃ§a

- Tem uma comunidade bem grande, entÃ£o para quase qualquer problema se encontra facilmente soluÃ§Ãµes em forums na internet.

- Suporta queries em paralelo que usam diferentes nÃºcleos do processador

Sendo assim, esse foi a modelagem do projeto que elaborei com base no problema:


![Diagrama Entidade Relacionamento](./docs/media/DER.png)

[VocÃª pode ver o DDL clicando aqui](./docs/DDL-DML.sql)

## Outras decisÃµes tÃ©cnicas

- Optei por adicionar redis para fazer cache no endpoint de listagem de produtos e restaurantes, assim aumentando a performance e diminuindo o processamento do lado do servidor, se esse projeto fosse para produÃ§Ã£o usando um serviÃ§o de custo dinÃ¢mico como Lambda da AWS, terÃ­amos uma reduÃ§Ã£o de custos significativa no longo prazo, alÃ©m de tornar a experiÃªncia do usuÃ¡rio final melhor por ter que esperar menos.
  - O cache estÃ¡ configurado para durar 1 minuto, porÃ©m isso seria algo parametrizÃ¡vel pela variÃ¡vel de ambiente `REDIS_CACHE_DURATION` e esse tempo seria decidido dependendo do cenÃ¡rio tivermos em ambiente de produÃ§Ã£o.
  - A chave do cache Ã© uma string gerada combinado a rota e os query params
  - Quando a API responde com dados em cache, sÃ£o adicionados os headers `cache_updated_at` e `cache_invalidation_at` para a aplicaÃ§Ã£o cliente que possa se integrar saber quando esses dados foram atualizados.

- Optei por utilizar UUID's ao invÃ©s de nÃºmeros sequenciais porque essa Ã© uma tÃ©cnica que pode garantir um pouco mais seguranÃ§a dado que seria mais difÃ­cil de descobrir os recursos da mesma natureza, sÃ£o praticamente infinitos e Ã© a melhor forma de identificar e relacionar e relacionar objetos dentre um grupo de API's ou bancos de dados distribuÃ­dos.

## Testes unitÃ¡rios

Para a maioria dos casos eu utilizei da prÃ¡tica TDD criando os testes antes de criar a funcionalidade.

- Para gerar cobertura de testes rode `yarn test --coverage`

**Cobertura de Testes**

![Cobertura de testes](./docs/media/coverage.png)

## O que poderia melhorar

- Acredito que eu deveria ter salvo os horÃ¡rios de funcionamento como um campo string apenas, acho que compliquei demais sem necessidade, acredito que eu sÃ³ precisaria ter feito dessa forma com validaÃ§Ãµes de dias da semana e horÃ¡rios se meu objetivo fosse trabalhar com uma agenda ou algo assim, por outro lado se fosse apenas exibir como uma descriÃ§Ã£o em um app de delivery uma simples string seria mais interessante rs ğŸ˜….

- Eu poderia colocar algumas lÃ³gicas pra tornar aqueles arquivos de Mock das repositories em factories e ao adicionar alguns testes de integraÃ§Ã£o usando a lib `supertest` pra fazer as requests e assim poder garantir o body que o endpoint estÃ¡ria retornando para o cliente.

- Eu poderia ter criado algumas funÃ§Ãµes privadas pra tornar a leitura da service mais fluÃ­da e isolando melhoras as responsabilidades, principalmente as services de update

## âŒ› Tempo decorrido para execuÃ§Ã£o das tarefas

> Tempo levado para finalizar: 22h 46min

- Modelar banco de dados e gerar script de geraÃ§Ã£o - 2h

- Configurar estrutura do projeto (pastas, database, redis, docker) - 2h 30min

- Cadastrar novos restaurantes - 2h 5min

- Alterar os dados um restaurante - 2h 6min

- Listar os dados de um restaurante - 1h 40min

- Adicionar horÃ¡rio de funcionamento em restaurantes - 2h

- Listar todos os restaurantes - 20min

- Excluir um restaurante - 51min

- Listar todos os produtos de um restaurante - 40min

- Criar um produto de um restaurante - 1h

- Alterar um produto de um restaurante - 1h 10min

- Excluir um produto de um restaurante - 25min

- Implementar melhorias e revisar cÃ³digo e documentaÃ§Ã£o - 4h

- Atualizar Readme - 2h

## ConsideraÃ§Ãµes finais

Fico a disposiÃ§Ã£o para tirar dÃºvidas e sempre estarei aberto a criticas construtivas e sugestÃµes de melhorias, obrigado pela atenÃ§Ã£o!

Contato: gabrieldnrodrigues@gmail.com

Linkedin: https://www.linkedin.com/in/gabrieldissotti/

> Algumas pessoas com quem trabalhei recentemente comentaram no meu perfil do linkedin sobre a experiÃªncia que tiveram em trabalhar comigo, vale dar uma olhada lÃ¡ ğŸ˜€.
